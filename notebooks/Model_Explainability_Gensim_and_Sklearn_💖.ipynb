{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Explainability Gensim and Sklearn ðŸ’–",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CALDISS-AAU/sdsphd19_coursematerials/blob/master/notebooks/Model_Explainability_Gensim_and_Sklearn_%F0%9F%92%96.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG-1tL_SMYGC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2ab96978-bfa4-43cf-de27-4adcd149d031"
      },
      "source": [
        "!pip install -qq -U gensim\n",
        "\n",
        "!wget -O imdb.zip -qq \"http://sds-datacrunch.aau.dk/public/imdb.zip\"\n",
        "!unzip imdb.zip\n",
        "\n",
        "\n",
        "!pip -q install eli5"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  imdb.zip\n",
            "  inflating: test.tsv                \n",
            "  inflating: train.tsv               \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112kB 2.7MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ7gvmkmTxH3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1acfa925-9a85-4ab5-babb-a2635f3ae965"
      },
      "source": [
        "# Read in the files and quickly print the size of the training and test set.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_df = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
        "test_df = pd.read_csv(\"test.tsv\", sep=\"\\t\")\n",
        "\n",
        "print(f'Train size = {len(train_df)}')\n",
        "print(f'Test size = {len(test_df)}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size = 25000\n",
            "Test size = 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XyFNu2QUCPn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ed4179ec-26a6-415f-ff61-b198b8a21add"
      },
      "source": [
        "# some basic text cleaning, removing HTML fragments (only a problem here)\n",
        "\n",
        "import re\n",
        "\n",
        "pattern = re.compile('<br /><br />')\n",
        "\n",
        "print(train_df['review'].iloc[3])\n",
        "print(pattern.subn(' ', train_df['review'].iloc[3])[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spoilers ahead if you want to call them that...<br /><br />I would almost recommend this film just so people can truly see a 1/10. Where to begin, we'll start from the top...<br /><br />THE STORY: Don't believe the premise - the movie has nothing to do with abandoned cars, and people finially understanding what the mysterious happenings are. It's a draub, basic, go to cabin movie with no intensity or \"effort\".<br /><br />THE SCREENPLAY: I usually give credit to indie screenwriters, it's hard work when you are starting out...but this is crap. The story is flat - it leaves you emotionless the entire movie. The dialogue is extremely weak and predictable boasting lines of \"Woah, you totally freaked me out\" and \"I was wondering if you'd uh...if you'd like to..uh, would you come to the cabin with me?\". It makes me want to rip out all my hair, one strand at a time and feed it to myself.<br /><br />THE CHARACTERS: HOLY CRAP!!!! Some have described the characters as flat, I want to take it one step further and say that they actually have a reverse character arch.. They actually start working on a parallel universe and almost start acting backwards...<br /><br />THE ACTORS: Worse than the characters are the actors. They take already poor written characters and add in terrible high school drama acting. The \"Woah you totally freaked me out\" was said so monotone and slow - like it was dumbed down. I could complain for hours on the actors alone.<br /><br />TECHNICAL: LIGHTING: An eight year old would be disappointed with lighting on this movie. Too shadowy in areas, too bleached in others. The director shouldn't use light as an emotion until he learns how to light a basic scene properly. Baby Steps! SOUND: How many sound guys does it take to make a really shotty sounding movie? 9. With that many sound guys this should sound amazing but quite the opposite has occured. There is one scene in particular that really sticks out, these guys are driving in a car and the sound of the car changes with every camera angle....WEAK! CAMERA: Learn to use it.<br /><br />Anyway, I'm running out of complaining space.....rent it - I dare you...Rent it and learn from it...give it a 1 rating..it deserves it.<br /><br />Signing off... Amanda Christmas\n",
            "Spoilers ahead if you want to call them that... I would almost recommend this film just so people can truly see a 1/10. Where to begin, we'll start from the top... THE STORY: Don't believe the premise - the movie has nothing to do with abandoned cars, and people finially understanding what the mysterious happenings are. It's a draub, basic, go to cabin movie with no intensity or \"effort\". THE SCREENPLAY: I usually give credit to indie screenwriters, it's hard work when you are starting out...but this is crap. The story is flat - it leaves you emotionless the entire movie. The dialogue is extremely weak and predictable boasting lines of \"Woah, you totally freaked me out\" and \"I was wondering if you'd uh...if you'd like to..uh, would you come to the cabin with me?\". It makes me want to rip out all my hair, one strand at a time and feed it to myself. THE CHARACTERS: HOLY CRAP!!!! Some have described the characters as flat, I want to take it one step further and say that they actually have a reverse character arch.. They actually start working on a parallel universe and almost start acting backwards... THE ACTORS: Worse than the characters are the actors. They take already poor written characters and add in terrible high school drama acting. The \"Woah you totally freaked me out\" was said so monotone and slow - like it was dumbed down. I could complain for hours on the actors alone. TECHNICAL: LIGHTING: An eight year old would be disappointed with lighting on this movie. Too shadowy in areas, too bleached in others. The director shouldn't use light as an emotion until he learns how to light a basic scene properly. Baby Steps! SOUND: How many sound guys does it take to make a really shotty sounding movie? 9. With that many sound guys this should sound amazing but quite the opposite has occured. There is one scene in particular that really sticks out, these guys are driving in a car and the sound of the car changes with every camera angle....WEAK! CAMERA: Learn to use it. Anyway, I'm running out of complaining space.....rent it - I dare you...Rent it and learn from it...give it a 1 rating..it deserves it. Signing off... Amanda Christmas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6his57E4UOod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc_UBRb4mpyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# application of the cleaning mask to everthing\n",
        "\n",
        "train_df['review'] = train_df['review'].apply(lambda text: pattern.subn(' ', text)[0])\n",
        "test_df['review'] = test_df['review'].apply(lambda text: pattern.subn(' ', text)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnQOtsYMBdLT",
        "colab_type": "code",
        "outputId": "0bca32fc-7357-453f-f80d-abdfd00308f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk6cQ2-JAgAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the dictionary builder\n",
        "from gensim.corpora.dictionary import Dictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik7Z-Mf0Avdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import stopwords\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OytIiL2JB2aH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize our texts and remove stopwords, also kick out numbers, lower everything\n",
        "\n",
        "train_tokens = train_df['review'].map(lambda t: [tok.lower() for tok in word_tokenize(t) if tok not in stop_words and tok.isalpha()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMahAgOECqz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_tokens = test_df['review'].map(lambda t: [tok.lower() for tok in word_tokenize(t) if tok not in stop_words and tok.isalpha()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMwmxQf_C3u-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate a dictionary\n",
        "dictionary = Dictionary(train_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa1nCVawDIVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Filter it for extreme stuff\n",
        "dictionary.filter_extremes(no_below = 10, no_above=0.4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7ukOKwdMTCMa",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from gensim.sklearn_api import LsiTransformer, Text2BowTransformer, TfIdfTransformer\n",
        "import numpy as np\n",
        "\n",
        "# Create stages for our pipeline (including gensim and sklearn models alike).\n",
        "bow = Text2BowTransformer(prune_at = 5000)\n",
        "tfidf = TfIdfTransformer(dictionary=dictionary) # Here you can add a custom fancy tokenizer in which you define more preprocessing...\n",
        "model = LsiTransformer(num_topics=300)\n",
        "clf = XGBClassifier()\n",
        "pipe = Pipeline([('BOW', bow), ('TFIDF', tfidf), ('features', model), ('classifier', clf)])\n",
        "\n",
        "# How well does our pipeline perform on the training set?\n",
        "score = pipe.fit(train_df['review'][:5000], train_df.is_positive[:5000]).score(test_df['review'][:5000], test_df.is_positive[:5000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "862119ab-e339-4ce1-a676-e3b1d3bf629e",
        "id": "iGBGuX8jTBr0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7418"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKDLBZ6jSD4K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "28bfaa20-835c-4407-ac2c-5dfeda4623df"
      },
      "source": [
        "doc = test_df['review'][0]\n",
        "print(doc)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A formulaic story with all the tired cliches. I was shocked that the horrible script became a movie! What a waste! How many ORIGINAL scripts are scattered around without being produced?   At the climax I could predict what will happen in every single shot.  Oh, and don't even get me started about the idiotic sexual tension between the gorgeous female cop and the paralyzed cop who can barely move a finger. YEAH RIGHT. I CAN BUY THAT. What next? Fingers porn?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-t26eBWSTEF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "24b7d609-bfe9-4e3e-a27f-07cb31b9db28"
      },
      "source": [
        "import eli5\n",
        "from eli5.lime import TextExplainer\n",
        "\n",
        "te = TextExplainer(random_state=42)\n",
        "te.fit(doc, pipe.predict_proba)\n",
        "te.show_prediction()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=0\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.655</b>, score <b>-0.640</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.401\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 86.07%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.239\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 83.98%); opacity: 0.85\" title=\"-0.101\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.27%); opacity: 0.83\" title=\"-0.057\">formulaic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 69.49%); opacity: 0.94\" title=\"-0.254\">story</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.77%); opacity: 0.83\" title=\"0.053\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.97%); opacity: 0.83\" title=\"0.052\">all</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.05%); opacity: 0.84\" title=\"-0.083\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.83%); opacity: 0.80\" title=\"-0.002\">tired</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.78%); opacity: 0.81\" title=\"0.026\">cliches</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 93.51%); opacity: 0.81\" title=\"-0.028\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.47%); opacity: 0.82\" title=\"0.041\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.63%); opacity: 0.83\" title=\"0.062\">shocked</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.42%); opacity: 0.85\" title=\"-0.097\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.93%); opacity: 0.84\" title=\"-0.068\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.17%); opacity: 0.93\" title=\"0.235\">horrible</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.11%); opacity: 0.86\" title=\"0.119\">script</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.68%); opacity: 0.81\" title=\"-0.011\">became</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.08%); opacity: 0.84\" title=\"0.075\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.64%); opacity: 0.83\" title=\"0.047\">movie</span><span style=\"opacity: 0.80\">! </span><span style=\"background-color: hsl(120, 100.00%, 83.99%); opacity: 0.85\" title=\"0.101\">what</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.66%); opacity: 0.83\" title=\"0.054\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 63.55%); opacity: 0.98\" title=\"0.328\">waste</span><span style=\"opacity: 0.80\">! </span><span style=\"background-color: hsl(120, 100.00%, 92.24%); opacity: 0.82\" title=\"0.036\">how</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.58%); opacity: 0.82\" title=\"0.034\">many</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.79%); opacity: 0.81\" title=\"0.026\">original</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.45%); opacity: 0.83\" title=\"0.063\">scripts</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.85%); opacity: 0.88\" title=\"0.151\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.24%); opacity: 0.82\" title=\"0.030\">scattered</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.60%); opacity: 0.87\" title=\"0.124\">around</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.71%); opacity: 0.81\" title=\"0.021\">without</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.93%); opacity: 0.82\" title=\"-0.045\">being</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.93%); opacity: 0.82\" title=\"-0.045\">produced</span><span style=\"opacity: 0.80\">?   </span><span style=\"background-color: hsl(120, 100.00%, 94.17%); opacity: 0.81\" title=\"0.024\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.36%); opacity: 0.81\" title=\"0.017\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.24%); opacity: 0.84\" title=\"0.082\">climax</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.00%); opacity: 0.82\" title=\"0.031\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.44%); opacity: 0.81\" title=\"-0.022\">could</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.44%); opacity: 0.81\" title=\"-0.022\">predict</span><span style=\"opacity: 0.80\"> what </span><span style=\"background-color: hsl(0, 100.00%, 61.26%); opacity: 0.99\" title=\"-0.358\">will</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.98%); opacity: 0.81\" title=\"0.025\">happen</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.22%); opacity: 0.85\" title=\"0.099\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.44%); opacity: 0.81\" title=\"0.022\">every</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.88%); opacity: 0.81\" title=\"0.015\">single</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.98%); opacity: 0.86\" title=\"0.111\">shot</span><span style=\"opacity: 0.80\">.  </span><span style=\"background-color: hsl(120, 100.00%, 86.05%); opacity: 0.84\" title=\"0.083\">oh</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 86.53%); opacity: 0.84\" title=\"-0.079\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.86%); opacity: 0.81\" title=\"-0.026\">don</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 83.25%); opacity: 0.86\" title=\"0.108\">t</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.375\">even</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 70.44%); opacity: 0.93\" title=\"0.243\">get</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.80%); opacity: 0.82\" title=\"-0.032\">me</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.56%); opacity: 0.83\" title=\"0.063\">started</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.56%); opacity: 0.83\" title=\"0.063\">about</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.54%); opacity: 0.86\" title=\"-0.105\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.96%); opacity: 0.81\" title=\"-0.025\">idiotic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.57%); opacity: 0.81\" title=\"0.016\">sexual</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.28%); opacity: 0.84\" title=\"-0.081\">tension</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.95%); opacity: 0.81\" title=\"0.010\">between</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.04%); opacity: 0.84\" title=\"-0.083\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.17%); opacity: 0.84\" title=\"-0.074\">gorgeous</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.46%); opacity: 0.81\" title=\"-0.022\">female</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.97%); opacity: 0.84\" title=\"-0.076\">cop</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.11%); opacity: 0.86\" title=\"-0.109\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.04%); opacity: 0.82\" title=\"0.044\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.33%); opacity: 0.80\" title=\"-0.008\">paralyzed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.50%); opacity: 0.81\" title=\"0.022\">cop</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 73.65%); opacity: 0.91\" title=\"-0.206\">who</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.48%); opacity: 0.87\" title=\"-0.125\">can</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.10%); opacity: 0.82\" title=\"0.044\">barely</span><span style=\"opacity: 0.80\"> move </span><span style=\"background-color: hsl(0, 100.00%, 90.98%); opacity: 0.82\" title=\"-0.045\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.59%); opacity: 0.81\" title=\"-0.016\">finger</span><span style=\"opacity: 0.80\">. yeah </span><span style=\"background-color: hsl(120, 100.00%, 96.08%); opacity: 0.81\" title=\"0.014\">right</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 99.47%); opacity: 0.80\" title=\"-0.001\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.54%); opacity: 0.80\" title=\"-0.007\">can</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.97%); opacity: 0.82\" title=\"-0.045\">buy</span><span style=\"opacity: 0.80\"> that. what </span><span style=\"background-color: hsl(120, 100.00%, 92.27%); opacity: 0.82\" title=\"0.036\">next</span><span style=\"opacity: 0.80\">? </span><span style=\"background-color: hsl(120, 100.00%, 98.41%); opacity: 0.80\" title=\"0.004\">fingers</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.88%); opacity: 0.82\" title=\"-0.032\">porn</span><span style=\"opacity: 0.80\">?</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    }
  ]
}